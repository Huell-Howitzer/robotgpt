import ast
import requests
import os
import time
import subprocess
import sys
from io import StringIO

from flask import session

from tasks import hyperloop
import astunparse
import black
import nltk
import openai
from dotenv import load_dotenv
from flask import Flask
from flask import jsonify
from flask import render_template
from flask import request
from flask import session
from flask import send_file
from flask import send_from_directory
from engine.main import Engine
from database.db import Database
from werkzeug.utils import secure_filename
from flask import redirect, render_template, request, url_for
from tasks import hyperloop
from utilities import key_utils

app = Flask(__name__, template_folder="templates")

load_dotenv()

db = Database()
db.init_db()


# Check if secret key is set in environment variable
if 'SECRET_KEY' in os.environ:
    app.secret_key = os.environ['SECRET_KEY']
else:
    # Generate a random secret key if not set in environment variable
    app.secret_key = key_utils.generate_secret_key()

# Get the absolute path to the prompt.txt file
prompt_file = os.path.abspath(os.path.join(os.path.dirname(__file__), "prompt.txt"))
api_key = os.getenv("OPENAI_API_KEY")
print(f"API Key: {api_key}")
engine = Engine()
database = engine.database


@app.route("/")
def index():
    theme = set_theme()
    return render_template("index.html", theme=theme)


from tasks import hyperloop


@app.route('/start_hyperloop', methods=['POST'])
def start_hyperloop():
    task = hyperloop.apply_async(
        args=[request.form['prompt'], request.form['expected_output'], request.form['similarity_threshold']])
    return jsonify({}), 202, {'Location': url_for('taskstatus', task_id=task.id)}


@app.route('/status/<task_id>')
def taskstatus(task_id):
    task = hyperloop.AsyncResult(task_id)
    if task.state == 'PENDING':
        response = {
            'state'     : task.state,
            'iteration' : 0,
            'similarity': 0
        }
    elif task.state != 'FAILURE':
        response = {
            'state'     : task.state,
            'iteration' : task.info.get('iteration', 0),
            'similarity': task.info.get('similarity', 0)
        }
    else:
        # task failed
        response = {
            'state'     : task.state,
            'iteration' : task.info.get('iteration', 0),
            'similarity': task.info.get('similarity', 0),
            'status'    : str(task.info)  # this is the exception raised
        }
    return jsonify(response)


def escape_quotes(s):
    s = s.replace("'", "\\'")
    s = s.replace('"', '\\"')
    return s


@app.route("/hyperloop", methods=["GET", "POST"])
def hyperloop():
    if request.method == "POST":
        # Handle POST request
        prompt = request.form.get("prompt")
        prompt = escape_quotes(prompt)
        expected_output = request.form.get("expected_output")
        similarity_threshold = float(request.form.get("similarity_threshold"))
        similarity = 0
        iteration_limit = 10  # Set the limit for maximum iterations
        iteration_count = 0
        while similarity < similarity_threshold and iteration_count < iteration_limit:
            iteration_count += 1
            generated_code = engine.generate_code(prompt, expected_output, similarity_threshold)
            # Save the prompt and expected output to the database
            prompt_tokens = len(nltk.word_tokenize(prompt))
            # Generate the code using the prompt and expected output
            completion_tokens = len(nltk.word_tokenize(generated_code)) - prompt_tokens
            total_tokens = prompt_tokens + completion_tokens
            mr_poop_response = engine.handle_request(prompt, expected_output, similarity_threshold)
            print("Mr. Poop:")
            print(mr_poop_response)
            response_id = mr_poop_response["id"]
            chatgpt_finish_reason = mr_poop_response["choices"][0]["finish_reason"]
            chatgpt_output = mr_poop_response["choices"][0]["message"]["content"]
            # Extract code from the chat model response
            extracted_code = engine.extract_code_from_chat_model(chatgpt_output)
            # The output from running the code generated by the model
            actual_output = engine.execute_code(extracted_code)
            # Similarity of the desired text specified in run.html to the actual output of the code generated by the model
            similarity = engine.calculate_similarity(expected_output, actual_output)
            # Create a new AI Model response that compares the desired text to the actual output and the similarity score then provides feedback to the model that is providing the code.
            headers = {
                "Authorization": f"Bearer {os.getenv('OPENAI_API_KEY')}",
                "Content-Type" : "application/json",
            }
            messages = [
                {"role"   : "system",
                 "content": f"You are assisting another agent. They are attempting to solve this puzzle: {prompt}"},
                {"role": "system", "content": f"They produced the following output: {extracted_code}"},
                {"role": "system", "content": f"This code when ran produces the following output: {actual_output}"},
                {"role": "system", "content": f"The code should produce the following output: {expected_output}"},
                {"role"   : "system",
                 "content": f"When comparing the desired text to the actual output, the similarity score is: {similarity}%."},
                {"role"   : "system",
                 "content": f"Please provide feedback to the agent to help them meet the goal of having matching outputs. "},
                {"role": "system", "content": f"Please communicate with the agent in the first-person"},
                {"role"   : "system",
                 "content": f"Make sure you provide them with the prompt: {prompt} and the expected output: {expected_output}"},
            ]
            # Mr. Pink's response handling
            try:
                mr_pink_response = requests.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers=headers,
                    json={
                        "model"      : "gpt-3.5-turbo-16k-0613",
                        "messages"   : messages,
                        "max_tokens" : 7050,
                        "temperature": 0.9,
                    },
                )
                mr_pink_response.raise_for_status()  # raises exception for HTTP errors
                mr_pink_response_data = mr_pink_response.json()
                print(f"Mr. Pink: {mr_pink_response_data}")
                mr_pink_output = mr_pink_response_data["choices"][0]["message"]["content"]
                chatgpt_output = mr_pink_output
                print(f"Iteration: {iteration_count}")
                print(f"Similarity: {similarity}%")
                print(f"Generated Code:\n{generated_code}")
                print(f"Actual Output:\n{actual_output}")
            except Exception as e:
                print(f"Failed to get response from Mr. Pink... Error: {str(e)}")
                return render_template("hyperloop.html",
                                       error=f"Failed to get response from Mr. Pink... Error: {str(e)}")

        return render_template(
            "hyperloop.html",
            api_key=api_key,
            prompt=chatgpt_output,
            expected_output=expected_output,
            generated_code=generated_code,
            code_output=actual_output,
            similarity=similarity,
            iteration=iteration_count
        )

    elif request.method == "GET":
        # Handle GET request
        return render_template("hyperloop.html", api_key=api_key, prompt="", expected_output="", generated_code="",
                               code_output="", similarity=None)
    else:
        return jsonify({"error": "Invalid request method."})


@app.route("/run", methods=["GET", "POST"])
def run():
    if request.method == "POST":
        # Handle POST request
        # Get the prompt and expected output from the form
        prompt = request.form.get("prompt")
        expected_output = request.form.get("expected_output")
        similarity_threshold = request.form.get("similarity_threshold")

        # Save the prompt and expected output to the database
        prompt_tokens = len(nltk.word_tokenize(prompt))

        # Generate the code using the prompt and expected output
        generated_code = engine.generate_code(
            prompt, expected_output, similarity_threshold
        )

        # Calculate the number of completion tokens
        try:
            completion_tokens = len(nltk.word_tokenize(generated_code)) - prompt_tokens
        except Exception as e:
            return render_template("run.html", error="Failed to generate code... Please try again.")

        # Calculate the total number of tokens
        total_tokens = prompt_tokens + completion_tokens

        # Get the response from the OpenAI API
        response = engine.handle_request(prompt, expected_output, similarity_threshold)

        if response:
            # Print the entire JSON response
            print(response)
            # Extract relevant data from the JSON response
            response_id = response["id"]
            chatgpt_finish_reason = response["choices"][0]["finish_reason"]
            chatgpt_output = response["choices"][0]["message"]["content"]
            # Extract code from the chat model response
            extracted_code = engine.extract_code_from_chat_model(chatgpt_output)
            # The output from running the code generated by the model
            actual_output = engine.execute_code(extracted_code)
            # Similarity of the desired text specified in run.html to the actual output of the code generated by the model
            similarity = engine.calculate_similarity(expected_output, actual_output)
            # If the similarity is greater than the threshold, then the code is valid
            if float(similarity) >= float(similarity_threshold):
                # Update the database
                engine.save_to_db(
                    user_input=prompt,
                    created=int(time.time()),
                    expected_output=expected_output,
                    actual_output=actual_output,  # or the actual output if you have it
                    similarity_score=similarity,  # or the similarity score if you have it
                    prompt_tokens=prompt_tokens,
                    completion_tokens=completion_tokens,
                    total_tokens=total_tokens,
                    response_id=response_id,
                    chatgpt_finish_reason=chatgpt_finish_reason,
                    chatgpt_output=chatgpt_output,
                    extracted_code=extracted_code,  # Add the extracted code parameter
                    api_response=response,  # pass the entire response dictionary as a single argument
                )

                return render_template("run.html", message="Code generated and saved to database.",
                                       generated_code=generated_code, actual_output=actual_output,
                                       similarity=similarity, api_key=api_key)
            else:

                return render_template("run.html", message="Code generated but did not meet similarity threshold.",
                                       generated_code=generated_code, actual_output=actual_output,
                                       similarity=similarity, api_key=api_key)

        else:
            return render_template("run.html", error="Failed to generate code. Please try again.", api_key=api_key)

    elif request.method == "GET":
        # Handle GET request
        return render_template(
            "run.html",
            api_key=api_key,
            prompt="",
            expected_output="",
            generated_code="",
            code_output="",
            similarity=None,
        )
    else:
        return jsonify({"error": "Invalid request method."})


def get_formatted_code():
    try:
        # Run the engine/main.py script and capture the output
        output = subprocess.check_output(
            ["python", "engine/main.py", prompt_file, expected_output, similarity_threshold]
        )

        # Extract the code from the output
        code = engine.extract_code_from_chat_model(output)

        # Format the code
        formatted_code = engine.format_code(code)

        # Return the formatted code
        return formatted_code
    except Exception as e:
        # Handle any errors that occur during execution
        error_message = str(e)
        return f"An error occurred during execution: {error_message}"


@app.route("/robot_framework/reports/report")
def serve_report():
    reports_dir = os.path.join(app.root_path, "flask_app/robot_framework", "reports")
    filename = "report.html"
    file_path = os.path.join(reports_dir, filename)

    if os.path.exists(file_path):
        return send_file(file_path)
    else:
        return "Report file not found."


@app.route("/robot_framework/reports/logs")
def serve_logs():
    logs_dir = os.path.join(app.root_path, "flask_app/robot_framework", "reports")
    filename = "logs.html"
    file_path = os.path.join(logs_dir, filename)

    if os.path.exists(file_path):
        return send_file(file_path)
    else:
        return "Log file not found."


@app.route("/docs/<path:filename>")
def serve_docs(filename):
    docs_dir = os.path.join(app.root_path, "templates", "docs", "html")
    return send_from_directory(docs_dir, filename)


@app.route("/about")
def about():
    return "About Page"


@app.route('/settings', methods=['GET', 'POST'])
def settings():
    if request.method == 'POST':
        theme = request.form.get('theme')
        session['theme'] = theme  # Update the theme in the session
    theme = session['theme']
    return render_template('settings.html', theme=theme)


def allowed_file(filename):
    ALLOWED_EXTENSIONS = {"txt", "pdf", "png", "jpg", "jpeg", "gif"}

    return "." in filename and filename.rsplit(".", 1)[1].lower() in ALLOWED_EXTENSIONS


@app.route("/tts", methods=["GET"])
def tts_page():
    # Code to render the TTS page
    return render_template("tts.html")


@app.route("/tts", methods=["POST"])
def process_audio():
    if "file" not in request.files:
        return jsonify({"error": "No file in the request"})

    _file = request.files["file"]

    if _file.filename == "":
        return jsonify({"error": "No file selected"})

    if _file and allowed_file(_file.filename):
        filename = secure_filename(_file.filename)
        filepath = os.path.join(app.config["UPLOAD_FOLDER"], filename)
        _file.save(filepath)

        try:
            transcript = engine.process_speech_to_text(filepath)
            if transcript:
                return jsonify({"filename": filename, "output": transcript})
            else:
                return jsonify({"error": "Audio processing failed"})
        except Exception as e:
            return jsonify({"error": str(e)})

    return jsonify({"error": "Invalid file"})


@app.before_request
def set_theme():
    if 'theme' not in session:
        session['theme'] = 'light'  # Set the default theme to 'light'


if __name__ == "__main__":
    database.init_db()
    app.run(host="0.0.0.0", port=5000)
